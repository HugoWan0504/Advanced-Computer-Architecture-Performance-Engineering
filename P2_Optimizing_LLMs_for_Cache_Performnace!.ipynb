{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The key is already registered\n",
      "Done loading notebook.py! We're good to go!\n"
     ]
    }
   ],
   "source": [
    "# Please execute/shift-return this cell everytime you run the notebook.  Don't edit it. \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from notebook import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cs203.is_response": true,
    "deletable": false,
    "editable": true
   },
   "source": [
    "<div class=\"namebox\">    \n",
    "Double Click to edit and enter your\n",
    "\n",
    "1.  Hugo Wan\n",
    "2.  twan012\n",
    "3.  twan012@ucr.edu\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deleteable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "<div style=\" font-size: 300% !important;\n",
    "    margin-top: 1.5em;\n",
    "    margin-bottom: 10px;\n",
    "    font-weight: bold;\n",
    "    line-height: 1.0;\n",
    "    text-align:center;\">\n",
    "Programming Assignment/Lab 2: Optimizing LLMs for Cache Performnace!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deleteable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "**Welcome to the first programming assignment/lab of CS203!**\n",
    "\n",
    "The main goals of this assignment/lab are:\n",
    "\n",
    "1. Get familiar with performance profiling tools.\n",
    "2. Get familiar with C/C++ and the development environment.\n",
    " \n",
    "This assignment/lab will be completed on **your own**. \n",
    "\n",
    "Check Gradescope for due date(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deleteable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "## Browser Compatibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deleteable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "We are still working out some bugs in some browsers.  Here's the current status:\n",
    "\n",
    "1.  Chrome -- well tested.  Preferred option.\n",
    "2.  Firefox -- seems ok, but not thoroughly tested.\n",
    "3.  Edge -- seems ok, but not thoroughly tested.\n",
    "4.  Safari -- not supported at the moment.\n",
    "5.  Internet Explorer -- not supported at the moment.\n",
    "\n",
    "At the moment, the authentication step must be done in Chrome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deleteable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "## Keeping Your assignment/lab Up-to-Date\n",
    "\n",
    "Occasionally, there will be changes made to the base repository after the\n",
    "lab is released.  This may include bug fixes and updates to this document.  We'll post on piazza/edstem when an update is available.\n",
    "\n",
    "In those cases, you can use the following commands to pull the changes from upstream and merge them into your code.  You'll need to do this at a shell.  It won't work properly in the notebook.  Save your notebook in the browser first.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deleteable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "```\n",
    "cd <your directory for this assignment/lab>git remote add upstream $(cat .starter_repo)  # You need to do this once each time you checkout a new assignment/lab. It will fail \n",
    "                                              # harmlessly if you run it more than once.\n",
    "cp assignment-lab.ipynb assignment-lab.backup.ipynb                 # Backup your work.\n",
    "git commit -am \"My progress so far.\"          # commit your work.\n",
    "git pull upstream main --allow-unrelated-histories -X theirs # pull the updates\n",
    "```\n",
    "\n",
    "Or you can use the script we provide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deleteable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: remote upstream already exists.\n",
      "cp: cannot stat 'assignment-lab.ipynb': No such file or directory\n",
      "[main c933c19] My progress so far.\n",
      " 3 files changed, 614 insertions(+), 92 deletions(-)\n",
      "From github.com:CS203UCR/2025fa-cs203-llm-memory-starter\n",
      " * branch            main       -> FETCH_HEAD\n",
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "# Be sure to click save to preseve your progress before updating\n",
    "! ./fix-repo\n",
    "! ./pull-updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deleteable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Then, reload this page in your browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deleteable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "## How To Use This Document\n",
    "\n",
    "You will use Jupyter Notebook to complete this assignment/lab.  You should be able to do much of this assignment/lab without leaving Jupyter Notebook.  The main exception will be some of the programming chanllenges.  The instructions will make it clear when you should use the terminal.\n",
    "\n",
    "### Running Code\n",
    "\n",
    "Jupyter Notebooks are made up of \"cells\".  Some have Markdown-formatted text in them (like this one).  Some have Python code (like the one below).\n",
    "\n",
    "For code cells, you press `shift-return` to execute the code.  Try it below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deleteable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm in python\n"
     ]
    }
   ],
   "source": [
    "print(\"I'm in python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deleteable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Code cells can also execute shell commands using the `!` operator.  Try it below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deleteable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm in a shell\n"
     ]
    }
   ],
   "source": [
    "!echo \"I'm in a shell\""
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "deleteable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Telling What The Notebook is Doing\n",
    "\n",
    "The notebook will only run one cell at a time, so if you press `shift-return` several times, the cells will wait for one another.  You can tell that a cell is waiting if it there's a `*` in the `[]` to the left the cell:\n",
    "\n",
    "![image.png](attachment:image.png)\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "deleteable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "You'll can also tell _where_ the notebook is executing by looking at the table of contents on the left.  The section with the currently-executing cell will be red:\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAADcAAAA1CAYAAADlE3NNAAABRGlDQ1BJQ0MgUHJvZmlsZQAAKJFjYGASSSwoyGFhYGDIzSspCnJ3UoiIjFJgf8rAycDPIMYgwyCSmFxc4BgQ4ANUwgCjUcG3awyMIPqyLsisHbud/s7f09wx77xWn4rBr1hM9SiAKyW1OBlI/wHitOSCohIGBsYUIFu5vKQAxO4AskWKgI4CsueA2OkQ9gYQOwnCPgJWExLkDGTfALIFkjMSgWYwvgCydZKQxNOR2FB7QYDHxdXHRyHAxNjQPJCAc0kHJakVJSDaOb+gsigzPaNEwREYSqkKnnnJejoKRgZGhgwMoDCHqP75FhyWjHWbEWKJwQwMhq1AQSGEWLYoA8Oe3wwMQrsRYlp5DAyCDQwM++MLEosS4Q5g/MZSnGZsBGGLhzEwcHb9//8C6FHuf0C79P7//8H7///vegYG9iIGhm4rACicXg0u2h90AAAAOGVYSWZNTQAqAAAACAABh2kABAAAAAEAAAAaAAAAAAACoAIABAAAAAEAAAA3oAMABAAAAAEAAAA1AAAAABCNvQ0AAAJGSURBVGgF7VkxayJBFP52XVC4YHNRxFoQRLSwvLTaWopgArkfYK2IlUViY5PzL1jZqI2dlbbaiWisREXUQnJYyF6S2WLvAgvZ3cwes8NMNTvz9r3ve9+beSwrnc/nV3A6ZE55abQEObeqK5QTyjGYAWW/3zMIiw4k6fV90HHFnhdxobCniTlEQjlzeWLPShmNRuyhooWI3JZWxnA4tGJOxdZuTHHmaFXJ//bDtXKKE9ncbDbYbremXMdiMXi9XlO2Vox2ux0cIVcqlTAej01hqVQqyOVypmw/M7pcLmg2m+h0OjgcDs6QU1X1Mxz6vqr+0edfmby8/Mbd3S0Wi4VWCfF43BlyXwFp993HxweNWCqVQr1eRzAYhJzJZJBIJEDKw0rG7YJw4r31eo1ut4tAIICnp18aMRJHbjQaqNVq6PV6GAwGTsR23OdkMtFipNNpXF190+PJpDaz2SwikQhWq5W+4aYJUY6McDj8Abbe53w+n2vLMhqNaqRms5kxuQ+rLntIJpMg4vT7fSyen3X0unL6igsnfr8fxWIRpM/9vL/X+hxpDVyQI3oUCgXk83mcTidUq1Xc3Pz42+darRY1zUKhEJbLpSl/19ffTdmZMSqXyyCtrd1uYzqdAlY/uOx+W1mN86+93ZjclKWRsoKcUVbcsCaUc4NKRhglchMZbfCwJn6EuFVFcaEI5RjMgDKfzxmERQeSdDweuW0Fiizze6coHo+HTg0w6IVv5bguS67JSZLE4GmhA4nrM8dvH3gXX+G5LN8AO2tDVwI9BI4AAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "deleteable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### What to Do Jupyter Notebook It Gets Stuck\n",
    "\n",
    "First, check if it's actually stuck: Some of the cells take a while, but they will usually provide some visual sign of progress.  If _nothing_ is happening for more than 10 seconds, it's probably stuck.\n",
    "\n",
    "To get it unstuck, you stop execution of the current cell with the \"interrupt button\":\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use VSCode\n",
    "\n",
    "The container that we build for CS203 provides a more friendly \"VSCode\" environment. To launch that environment, you should find and press the `+` icon near the file menu.\n",
    "\n",
    "![plus.png](plus.png)\n",
    "\n",
    "The interface will move to a launcher where you may find the following VSCode icon.\n",
    "\n",
    "![vscode.png](vscode.png)\n",
    "\n",
    "Press that icon and then you can enjoy VSCode environment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "# Large Language Models\n",
    "\n",
    "Large Language Models (LLMs) are a type of artificial intelligence that can understand and generate human-like text. They are built upon a neural network architecture called the Transformer, which allows them to process and learn from vast amounts of text data. Through a process called \"pretraining,\" LLMs learn to predict the next word in a sequence, effectively learning the patterns, grammar, and even some factual knowledge embedded in the training data. This pretraining typically involves massive datasets and significant computational resources. After pretraining, LLMs can be fine-tuned for specific tasks like summarization, translation, or question answering.\n",
    "\n",
    "This project is based on `llm.c` repository by Andrej Karpathy provides a minimalist implementation of large language model training in pure C/CUDA, aiming for simplicity and efficiency without relying on large frameworks like PyTorch. The `train_gpt2.h` file within this repository provides a set of primitives that supports training a GPT-2 model.\n",
    "\n",
    "Here's how the main function of `train_gpt2.c` uses the functions in `train_gpt2.h` in implementing the training:\n",
    "\n",
    "* **GPT-2 Reproduction:** The code is specifically designed to reproduce the training of a GPT-2 (124M parameter) model. This involves implementing the forward and backward passes for all the Transformer layers that constitute the GPT-2 architecture.\n",
    "* **Data Handling:** It handles the loading and processing of training data, such as the tokenized Tiny Shakespeare dataset, and works with a GPT-2 tokenizer.\n",
    "* **Optimization:** The training process uses the AdamW optimizer, a common choice for training deep learning models, to update the model's parameters based on the calculated gradients.\n",
    "* **Training Loop:** The `main` function in `train_gpt2.c` contains the primary training loop. This loop iteratively performs the following steps:\n",
    "    1.  **Forward Pass:** Input data (a batch of sequences) is fed through the GPT-2 model to produce output logits (predictions for the next token).\n",
    "    2.  **Loss Calculation:** The difference between the predicted logits and the actual next tokens is quantified using a loss function (e.g., cross-entropy loss).\n",
    "    3.  **Backward Pass (Backpropagation):** Gradients are calculated, indicating how much each parameter in the model contributes to the loss. This is done by propagating the error backward through the network.\n",
    "    4.  **Parameter Update:** The AdamW optimizer uses these gradients to adjust the model's weights, aiming to minimize the loss in subsequent steps.\n",
    "* **Simplified Approach:** Unlike more complex training setups, `train_gpt2.c` allocates all its GPU (or CPU) memory at the start, ensuring a constant memory footprint during training. It focuses on the fundamental arithmetic operations of neural network training, demonstrating that the process can be boiled down to a series of simple computations on float arrays.\n",
    "\n",
    "Due to the significance of LLMs in modern AI applications, the performance of training LLM models matters when deploying applications. Based on Amdahl's Law, we should target the most time consuming function first. Even without any prior knowledge about, we can still know what's the most time-consuming function when training an LLM model through `perf record` and `perf report` as below.\n",
    "\n",
    "**Notice: Training would take quite a long time -- about 6-10 minutes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "→ cuDNN is manually disabled by default, run make with `USE_CUDNN=1` to try to enable\n",
      "✓ OpenMP found\n",
      "✗ NCCL is not found, disabling multi-GPU support\n",
      "---> On Linux you can try install NCCL with `sudo apt install libnccl2 libnccl-dev`\n",
      "✓ MPI enabled\n",
      "---------------------------------------------\n",
      "rm -f train_gpt2 test_gpt2 my_test_gpt2 my_train_gpt2\n",
      "rm -f build/*.o\n",
      "---------------------------------------------\n",
      "→ cuDNN is manually disabled by default, run make with `USE_CUDNN=1` to try to enable\n",
      "✓ OpenMP found\n",
      "✗ NCCL is not found, disabling multi-GPU support\n",
      "---> On Linux you can try install NCCL with `sudo apt install libnccl2 libnccl-dev`\n",
      "✓ MPI enabled\n",
      "---------------------------------------------\n",
      "cc -Ofast -Wno-unused-result -Wno-ignored-pragmas -Wno-unknown-attributes -DHAVE_LINUX_PERF_EVENT_H -march=native -g   train_gpt2.h train_gpt2.c perfstats.o -lm -o train_gpt2\n"
     ]
    }
   ],
   "source": [
    "# Compile the code with the debug flag.\n",
    "! make clean; make OPT_CFLAGS=\"-g\" train_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the cloud for: twan012@ucr.edu\n",
      "WARNING: Kernel address maps (/proc/{kallsyms,modules}) are restricted,\n",
      "check /proc/sys/kernel/kptr_restrict and /proc/sys/kernel/perf_event_paranoid.\n",
      "\n",
      "Samples in kernel functions may not be resolved if a suitable vmlinux\n",
      "file is not found in the buildid cache or in the vmlinux path.\n",
      "\n",
      "Samples in kernel modules won't be resolved at all.\n",
      "\n",
      "If some relocation was applied (e.g. kexec) symbols may be misresolved\n",
      "even with a suitable vmlinux or kallsyms file.\n",
      "\n",
      "Couldn't record kernel reference relocation symbol\n",
      "Symbol resolution may be skewed if relocation was used (e.g. kexec).\n",
      "Check /proc/kallsyms permission or run as root.\n",
      "[GPT-2]\n",
      "max_seq_len: 1024\n",
      "vocab_size: 50257\n",
      "padded_vocab_size: 50304\n",
      "num_layers: 12\n",
      "num_heads: 12\n",
      "channels: 768\n",
      "num_parameters: 124475904\n",
      "train dataset num_batches: 1192\n",
      "val dataset num_batches: 128\n",
      "num_activations: 73347840\n",
      "val loss 5.325522\n",
      "step 0: train loss 4.677772 (took 17894.584162 ms)\n",
      "step 1: train loss 5.191521 (took 17196.880805 ms)\n",
      "step 2: train loss 4.438628 (took 17371.056769 ms)\n",
      "step 3: train loss 4.138455 (took 17162.789283 ms)\n",
      "step 4: train loss 4.144234 (took 17135.756937 ms)\n",
      "step 5: train loss 3.834685 (took 17387.487346 ms)\n",
      "step 6: train loss 4.298057 (took 17288.068637 ms)\n",
      "step 7: train loss 4.280747 (took 17325.995173 ms)\n",
      "step 8: train loss 4.249753 (took 17215.577076 ms)\n",
      "step 9: train loss 4.391605 (took 17248.023112 ms)\n",
      "val loss 4.416495\n",
      "generating:\n",
      "---\n",
      "grievously allowed it\n",
      "That had shall say to him:\n",
      "It is fair\n",
      "that it be paid that a villager came\n",
      "To the\n",
      "---\n",
      "step 10: train loss 3.912614 (took 17519.777542 ms)\n",
      "Total: 290058.542588 ms\n",
      "[ perf record: Woken up 179 times to write data ]\n",
      "[ perf record: Captured and wrote 0.000 MB (null) ]\n"
     ]
    }
   ],
   "source": [
    "# Run the \"real\" training process and record the profiled information.\n",
    "! cs203 run \"perf record ./train_gpt2 > perf.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss: 0</th>\n",
       "      <th>Loss: 1</th>\n",
       "      <th>Loss: 2</th>\n",
       "      <th>Loss: 3</th>\n",
       "      <th>Loss: 4</th>\n",
       "      <th>Loss: 5</th>\n",
       "      <th>Loss: 6</th>\n",
       "      <th>Loss: 7</th>\n",
       "      <th>Loss: 8</th>\n",
       "      <th>Loss: 9</th>\n",
       "      <th>Loss: 10</th>\n",
       "      <th>IC</th>\n",
       "      <th>Cycles</th>\n",
       "      <th>CPI</th>\n",
       "      <th>CT</th>\n",
       "      <th>ET</th>\n",
       "      <th>L1_dcache_miss_rate</th>\n",
       "      <th>L1_dcache_misses</th>\n",
       "      <th>L1_dcache_accesses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.677772</td>\n",
       "      <td>5.191521</td>\n",
       "      <td>4.438628</td>\n",
       "      <td>4.138455</td>\n",
       "      <td>4.144234</td>\n",
       "      <td>3.834685</td>\n",
       "      <td>4.298057</td>\n",
       "      <td>4.280747</td>\n",
       "      <td>4.249753</td>\n",
       "      <td>4.391605</td>\n",
       "      <td>3.912614</td>\n",
       "      <td>1505597537395</td>\n",
       "      <td>659436566497</td>\n",
       "      <td>0.43799</td>\n",
       "      <td>0.439858</td>\n",
       "      <td>290.058261</td>\n",
       "      <td>0.091808</td>\n",
       "      <td>82541685330</td>\n",
       "      <td>899065207843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loss: 0   Loss: 1   Loss: 2   Loss: 3   Loss: 4   Loss: 5   Loss: 6  \\\n",
       "0  4.677772  5.191521  4.438628  4.138455  4.144234  3.834685  4.298057   \n",
       "\n",
       "    Loss: 7   Loss: 8   Loss: 9  Loss: 10             IC        Cycles  \\\n",
       "0  4.280747  4.249753  4.391605  3.912614  1505597537395  659436566497   \n",
       "\n",
       "       CPI        CT          ET   L1_dcache_miss_rate  L1_dcache_misses  \\\n",
       "0  0.43799  0.439858  290.058261              0.091808       82541685330   \n",
       "\n",
       "   L1_dcache_accesses  \n",
       "0        899065207843  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "render_csv(\"baseline.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Now, we can use `perf report` to interpret the output as human-readable content using the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:\n",
      "Kernel address maps (/proc/{kallsyms,modules}) were restricted.\n",
      "\n",
      "Check /proc/sys/kernel/kptr_restrict before running 'perf record'.\n",
      "\n",
      "As no suitable kallsyms nor vmlinux was found, kernel samples\n",
      "can't be resolved.\n",
      "\n",
      "Samples in kernel modules can't be resolved as well.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Figure out the most time-consuming function.\n",
    "! perf report --stdio > perf.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "The output file is really long, and the goal is never about optimizing everything. So we can use `head` command to see what's in the first 20 lines of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# To display the perf.data header info, please use --header/--header-only options.\n",
      "#\n",
      "#\n",
      "# Total Lost Samples: 0\n",
      "#\n",
      "# Samples: 974K of event 'cycles'\n",
      "# Event count (approx.): 820183311972\n",
      "#\n",
      "# Overhead  Command     Shared Object     Symbol                          \n",
      "# ........  ..........  ................  ................................\n",
      "#\n",
      "    31.78%  train_gpt2  train_gpt2        [.] matmul_backward\n",
      "    24.36%  train_gpt2  train_gpt2        [.] matmul_forward\n",
      "    20.57%  train_gpt2  train_gpt2        [.] gpt2_backward\n",
      "    12.96%  train_gpt2  train_gpt2        [.] matmul_forward.constprop.0\n",
      "     3.16%  train_gpt2  libm-2.31.so      [.] __expm1f\n",
      "     1.30%  train_gpt2  libm-2.31.so      [.] __tanhf\n",
      "     1.06%  train_gpt2  train_gpt2        [.] main\n",
      "     0.93%  train_gpt2  train_gpt2        [.] attention_backward\n",
      "     0.79%  train_gpt2  [unknown]         [k] 0xffffffff9cb0cdb5\n"
     ]
    }
   ],
   "source": [
    "! head -20 perf.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Have you find which function takes the most significant amount of time? Is it the same as our last lab?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Through profiling the training process, we know `matmul_backward` in `train_gpt2.h` is the most time-consuming function. Let's dive in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #F00 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #04D } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #00F; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #800 } /* Name.Constant */\n",
       ".output_html .nd { color: #A2F } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #00F } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #00F; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #A2F; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #BBB } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #00F } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"c1\">// train_gpt2.h:226-263 (38 lines)</span>\n",
       "<span class=\"kt\">void</span><span class=\"w\"> </span><span class=\"nf\">matmul_backward</span><span class=\"p\">(</span><span class=\"kt\">float</span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">dinp</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"kt\">float</span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">dweight</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"kt\">float</span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">dbias</span><span class=\"p\">,</span>\n",
       "<span class=\"w\">                     </span><span class=\"k\">const</span><span class=\"w\"> </span><span class=\"kt\">float</span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">dout</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"k\">const</span><span class=\"w\"> </span><span class=\"kt\">float</span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">inp</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"k\">const</span><span class=\"w\"> </span><span class=\"kt\">float</span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">weight</span><span class=\"p\">,</span>\n",
       "<span class=\"w\">                     </span><span class=\"kt\">int</span><span class=\"w\"> </span><span class=\"n\">B</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"kt\">int</span><span class=\"w\"> </span><span class=\"n\">T</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"kt\">int</span><span class=\"w\"> </span><span class=\"n\">C</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"kt\">int</span><span class=\"w\"> </span><span class=\"n\">OC</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"p\">{</span>\n",
       "<span class=\"w\">    </span><span class=\"c1\">// most of the running time is spent here and in matmul_forward</span>\n",
       "<span class=\"w\">    </span><span class=\"c1\">// this backward could be done in a single &quot;round&quot; of loops</span>\n",
       "<span class=\"w\">    </span><span class=\"c1\">// but that doesn&#39;t afford an efficient parallelization strategy</span>\n",
       "<span class=\"w\">    </span><span class=\"c1\">// backward into inp first, parallelize over B,T</span>\n",
       "\n",
       "<span class=\"w\">    </span><span class=\"k\">for</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"kt\">int</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"w\"> </span><span class=\"o\">&lt;</span><span class=\"w\"> </span><span class=\"n\">B</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"o\">++</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"p\">{</span>\n",
       "<span class=\"w\">        </span><span class=\"k\">for</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"kt\">int</span><span class=\"w\"> </span><span class=\"n\">t</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"n\">t</span><span class=\"w\"> </span><span class=\"o\">&lt;</span><span class=\"w\"> </span><span class=\"n\">T</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"n\">t</span><span class=\"o\">++</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"p\">{</span>\n",
       "<span class=\"w\">            </span><span class=\"k\">const</span><span class=\"w\"> </span><span class=\"kt\">float</span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">dout_bt</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">dout</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"w\"> </span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">T</span><span class=\"w\"> </span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">OC</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\"> </span><span class=\"n\">t</span><span class=\"w\"> </span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">OC</span><span class=\"p\">;</span>\n",
       "<span class=\"w\">            </span><span class=\"kt\">float</span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">dinp_bt</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">dinp</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"w\"> </span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">T</span><span class=\"w\"> </span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">C</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\"> </span><span class=\"n\">t</span><span class=\"w\"> </span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">C</span><span class=\"p\">;</span>\n",
       "<span class=\"w\">            </span><span class=\"k\">for</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"kt\">int</span><span class=\"w\"> </span><span class=\"n\">o</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"n\">o</span><span class=\"w\"> </span><span class=\"o\">&lt;</span><span class=\"w\"> </span><span class=\"n\">OC</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"n\">o</span><span class=\"o\">++</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"p\">{</span>\n",
       "<span class=\"w\">                </span><span class=\"k\">const</span><span class=\"w\"> </span><span class=\"kt\">float</span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">wrow</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">weight</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\"> </span><span class=\"n\">o</span><span class=\"o\">*</span><span class=\"n\">C</span><span class=\"p\">;</span>\n",
       "<span class=\"w\">                </span><span class=\"kt\">float</span><span class=\"w\"> </span><span class=\"n\">d</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">dout_bt</span><span class=\"p\">[</span><span class=\"n\">o</span><span class=\"p\">];</span>\n",
       "<span class=\"w\">                </span><span class=\"k\">for</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"kt\">int</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"w\"> </span><span class=\"o\">&lt;</span><span class=\"w\"> </span><span class=\"n\">C</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"p\">{</span>\n",
       "<span class=\"w\">                    </span><span class=\"n\">dinp_bt</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"o\">+=</span><span class=\"w\"> </span><span class=\"n\">wrow</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">d</span><span class=\"p\">;</span>\n",
       "<span class=\"w\">                </span><span class=\"p\">}</span>\n",
       "<span class=\"w\">            </span><span class=\"p\">}</span>\n",
       "<span class=\"w\">        </span><span class=\"p\">}</span>\n",
       "<span class=\"w\">    </span><span class=\"p\">}</span>\n",
       "<span class=\"w\">    </span><span class=\"c1\">// backward into weight/bias, parallelize over output channels OC</span>\n",
       "<span class=\"w\">    </span><span class=\"k\">for</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"kt\">int</span><span class=\"w\"> </span><span class=\"n\">o</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"n\">o</span><span class=\"w\"> </span><span class=\"o\">&lt;</span><span class=\"w\"> </span><span class=\"n\">OC</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"n\">o</span><span class=\"o\">++</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"p\">{</span>\n",
       "<span class=\"w\">        </span><span class=\"k\">for</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"kt\">int</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"w\"> </span><span class=\"o\">&lt;</span><span class=\"w\"> </span><span class=\"n\">B</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"o\">++</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"p\">{</span>\n",
       "<span class=\"w\">            </span><span class=\"k\">for</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"kt\">int</span><span class=\"w\"> </span><span class=\"n\">t</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"n\">t</span><span class=\"w\"> </span><span class=\"o\">&lt;</span><span class=\"w\"> </span><span class=\"n\">T</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"n\">t</span><span class=\"o\">++</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"p\">{</span>\n",
       "<span class=\"w\">                </span><span class=\"k\">const</span><span class=\"w\"> </span><span class=\"kt\">float</span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">dout_bt</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">dout</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"w\"> </span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">T</span><span class=\"w\"> </span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">OC</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\"> </span><span class=\"n\">t</span><span class=\"w\"> </span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">OC</span><span class=\"p\">;</span>\n",
       "<span class=\"w\">                </span><span class=\"k\">const</span><span class=\"w\"> </span><span class=\"kt\">float</span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">inp_bt</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">inp</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"w\"> </span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">T</span><span class=\"w\"> </span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">C</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\"> </span><span class=\"n\">t</span><span class=\"w\"> </span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">C</span><span class=\"p\">;</span>\n",
       "<span class=\"w\">                </span><span class=\"kt\">float</span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">dwrow</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">dweight</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\"> </span><span class=\"n\">o</span><span class=\"o\">*</span><span class=\"n\">C</span><span class=\"p\">;</span>\n",
       "<span class=\"w\">                </span><span class=\"kt\">float</span><span class=\"w\"> </span><span class=\"n\">d</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">dout_bt</span><span class=\"p\">[</span><span class=\"n\">o</span><span class=\"p\">];</span>\n",
       "<span class=\"w\">                </span><span class=\"k\">if</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"n\">dbias</span><span class=\"w\"> </span><span class=\"o\">!=</span><span class=\"w\"> </span><span class=\"nb\">NULL</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"> </span><span class=\"n\">dbias</span><span class=\"p\">[</span><span class=\"n\">o</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"o\">+=</span><span class=\"w\"> </span><span class=\"n\">d</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"p\">}</span>\n",
       "<span class=\"w\">                </span><span class=\"k\">for</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"kt\">int</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"w\"> </span><span class=\"o\">&lt;</span><span class=\"w\"> </span><span class=\"n\">C</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"p\">{</span>\n",
       "<span class=\"w\">                    </span><span class=\"n\">dwrow</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"o\">+=</span><span class=\"w\"> </span><span class=\"n\">inp_bt</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">d</span><span class=\"p\">;</span>\n",
       "<span class=\"w\">                </span><span class=\"p\">}</span>\n",
       "<span class=\"w\">            </span><span class=\"p\">}</span>\n",
       "<span class=\"w\">        </span><span class=\"p\">}</span>\n",
       "<span class=\"w\">    </span><span class=\"p\">}</span>\n",
       "\n",
       "<span class=\"p\">}</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{c+c1}{// train\\PYZus{}gpt2.h:226\\PYZhy{}263 (38 lines)}\n",
       "\\PY{k+kt}{void}\\PY{+w}{ }\\PY{n+nf}{matmul\\PYZus{}backward}\\PY{p}{(}\\PY{k+kt}{float}\\PY{o}{*}\\PY{+w}{ }\\PY{n}{dinp}\\PY{p}{,}\\PY{+w}{ }\\PY{k+kt}{float}\\PY{o}{*}\\PY{+w}{ }\\PY{n}{dweight}\\PY{p}{,}\\PY{+w}{ }\\PY{k+kt}{float}\\PY{o}{*}\\PY{+w}{ }\\PY{n}{dbias}\\PY{p}{,}\n",
       "\\PY{+w}{                     }\\PY{k}{const}\\PY{+w}{ }\\PY{k+kt}{float}\\PY{o}{*}\\PY{+w}{ }\\PY{n}{dout}\\PY{p}{,}\\PY{+w}{ }\\PY{k}{const}\\PY{+w}{ }\\PY{k+kt}{float}\\PY{o}{*}\\PY{+w}{ }\\PY{n}{inp}\\PY{p}{,}\\PY{+w}{ }\\PY{k}{const}\\PY{+w}{ }\\PY{k+kt}{float}\\PY{o}{*}\\PY{+w}{ }\\PY{n}{weight}\\PY{p}{,}\n",
       "\\PY{+w}{                     }\\PY{k+kt}{int}\\PY{+w}{ }\\PY{n}{B}\\PY{p}{,}\\PY{+w}{ }\\PY{k+kt}{int}\\PY{+w}{ }\\PY{n}{T}\\PY{p}{,}\\PY{+w}{ }\\PY{k+kt}{int}\\PY{+w}{ }\\PY{n}{C}\\PY{p}{,}\\PY{+w}{ }\\PY{k+kt}{int}\\PY{+w}{ }\\PY{n}{OC}\\PY{p}{)}\\PY{+w}{ }\\PY{p}{\\PYZob{}}\n",
       "\\PY{+w}{    }\\PY{c+c1}{// most of the running time is spent here and in matmul\\PYZus{}forward}\n",
       "\\PY{+w}{    }\\PY{c+c1}{// this backward could be done in a single \\PYZdq{}round\\PYZdq{} of loops}\n",
       "\\PY{+w}{    }\\PY{c+c1}{// but that doesn\\PYZsq{}t afford an efficient parallelization strategy}\n",
       "\\PY{+w}{    }\\PY{c+c1}{// backward into inp first, parallelize over B,T}\n",
       "\n",
       "\\PY{+w}{    }\\PY{k}{for}\\PY{+w}{ }\\PY{p}{(}\\PY{k+kt}{int}\\PY{+w}{ }\\PY{n}{b}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{l+m+mi}{0}\\PY{p}{;}\\PY{+w}{ }\\PY{n}{b}\\PY{+w}{ }\\PY{o}{\\PYZlt{}}\\PY{+w}{ }\\PY{n}{B}\\PY{p}{;}\\PY{+w}{ }\\PY{n}{b}\\PY{o}{+}\\PY{o}{+}\\PY{p}{)}\\PY{+w}{ }\\PY{p}{\\PYZob{}}\n",
       "\\PY{+w}{        }\\PY{k}{for}\\PY{+w}{ }\\PY{p}{(}\\PY{k+kt}{int}\\PY{+w}{ }\\PY{n}{t}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{l+m+mi}{0}\\PY{p}{;}\\PY{+w}{ }\\PY{n}{t}\\PY{+w}{ }\\PY{o}{\\PYZlt{}}\\PY{+w}{ }\\PY{n}{T}\\PY{p}{;}\\PY{+w}{ }\\PY{n}{t}\\PY{o}{+}\\PY{o}{+}\\PY{p}{)}\\PY{+w}{ }\\PY{p}{\\PYZob{}}\n",
       "\\PY{+w}{            }\\PY{k}{const}\\PY{+w}{ }\\PY{k+kt}{float}\\PY{o}{*}\\PY{+w}{ }\\PY{n}{dout\\PYZus{}bt}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{n}{dout}\\PY{+w}{ }\\PY{o}{+}\\PY{+w}{ }\\PY{n}{b}\\PY{+w}{ }\\PY{o}{*}\\PY{+w}{ }\\PY{n}{T}\\PY{+w}{ }\\PY{o}{*}\\PY{+w}{ }\\PY{n}{OC}\\PY{+w}{ }\\PY{o}{+}\\PY{+w}{ }\\PY{n}{t}\\PY{+w}{ }\\PY{o}{*}\\PY{+w}{ }\\PY{n}{OC}\\PY{p}{;}\n",
       "\\PY{+w}{            }\\PY{k+kt}{float}\\PY{o}{*}\\PY{+w}{ }\\PY{n}{dinp\\PYZus{}bt}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{n}{dinp}\\PY{+w}{ }\\PY{o}{+}\\PY{+w}{ }\\PY{n}{b}\\PY{+w}{ }\\PY{o}{*}\\PY{+w}{ }\\PY{n}{T}\\PY{+w}{ }\\PY{o}{*}\\PY{+w}{ }\\PY{n}{C}\\PY{+w}{ }\\PY{o}{+}\\PY{+w}{ }\\PY{n}{t}\\PY{+w}{ }\\PY{o}{*}\\PY{+w}{ }\\PY{n}{C}\\PY{p}{;}\n",
       "\\PY{+w}{            }\\PY{k}{for}\\PY{+w}{ }\\PY{p}{(}\\PY{k+kt}{int}\\PY{+w}{ }\\PY{n}{o}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{l+m+mi}{0}\\PY{p}{;}\\PY{+w}{ }\\PY{n}{o}\\PY{+w}{ }\\PY{o}{\\PYZlt{}}\\PY{+w}{ }\\PY{n}{OC}\\PY{p}{;}\\PY{+w}{ }\\PY{n}{o}\\PY{o}{+}\\PY{o}{+}\\PY{p}{)}\\PY{+w}{ }\\PY{p}{\\PYZob{}}\n",
       "\\PY{+w}{                }\\PY{k}{const}\\PY{+w}{ }\\PY{k+kt}{float}\\PY{o}{*}\\PY{+w}{ }\\PY{n}{wrow}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{n}{weight}\\PY{+w}{ }\\PY{o}{+}\\PY{+w}{ }\\PY{n}{o}\\PY{o}{*}\\PY{n}{C}\\PY{p}{;}\n",
       "\\PY{+w}{                }\\PY{k+kt}{float}\\PY{+w}{ }\\PY{n}{d}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{n}{dout\\PYZus{}bt}\\PY{p}{[}\\PY{n}{o}\\PY{p}{]}\\PY{p}{;}\n",
       "\\PY{+w}{                }\\PY{k}{for}\\PY{+w}{ }\\PY{p}{(}\\PY{k+kt}{int}\\PY{+w}{ }\\PY{n}{i}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{l+m+mi}{0}\\PY{p}{;}\\PY{+w}{ }\\PY{n}{i}\\PY{+w}{ }\\PY{o}{\\PYZlt{}}\\PY{+w}{ }\\PY{n}{C}\\PY{p}{;}\\PY{+w}{ }\\PY{n}{i}\\PY{o}{+}\\PY{o}{+}\\PY{p}{)}\\PY{+w}{ }\\PY{p}{\\PYZob{}}\n",
       "\\PY{+w}{                    }\\PY{n}{dinp\\PYZus{}bt}\\PY{p}{[}\\PY{n}{i}\\PY{p}{]}\\PY{+w}{ }\\PY{o}{+}\\PY{o}{=}\\PY{+w}{ }\\PY{n}{wrow}\\PY{p}{[}\\PY{n}{i}\\PY{p}{]}\\PY{+w}{ }\\PY{o}{*}\\PY{+w}{ }\\PY{n}{d}\\PY{p}{;}\n",
       "\\PY{+w}{                }\\PY{p}{\\PYZcb{}}\n",
       "\\PY{+w}{            }\\PY{p}{\\PYZcb{}}\n",
       "\\PY{+w}{        }\\PY{p}{\\PYZcb{}}\n",
       "\\PY{+w}{    }\\PY{p}{\\PYZcb{}}\n",
       "\\PY{+w}{    }\\PY{c+c1}{// backward into weight/bias, parallelize over output channels OC}\n",
       "\\PY{+w}{    }\\PY{k}{for}\\PY{+w}{ }\\PY{p}{(}\\PY{k+kt}{int}\\PY{+w}{ }\\PY{n}{o}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{l+m+mi}{0}\\PY{p}{;}\\PY{+w}{ }\\PY{n}{o}\\PY{+w}{ }\\PY{o}{\\PYZlt{}}\\PY{+w}{ }\\PY{n}{OC}\\PY{p}{;}\\PY{+w}{ }\\PY{n}{o}\\PY{o}{+}\\PY{o}{+}\\PY{p}{)}\\PY{+w}{ }\\PY{p}{\\PYZob{}}\n",
       "\\PY{+w}{        }\\PY{k}{for}\\PY{+w}{ }\\PY{p}{(}\\PY{k+kt}{int}\\PY{+w}{ }\\PY{n}{b}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{l+m+mi}{0}\\PY{p}{;}\\PY{+w}{ }\\PY{n}{b}\\PY{+w}{ }\\PY{o}{\\PYZlt{}}\\PY{+w}{ }\\PY{n}{B}\\PY{p}{;}\\PY{+w}{ }\\PY{n}{b}\\PY{o}{+}\\PY{o}{+}\\PY{p}{)}\\PY{+w}{ }\\PY{p}{\\PYZob{}}\n",
       "\\PY{+w}{            }\\PY{k}{for}\\PY{+w}{ }\\PY{p}{(}\\PY{k+kt}{int}\\PY{+w}{ }\\PY{n}{t}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{l+m+mi}{0}\\PY{p}{;}\\PY{+w}{ }\\PY{n}{t}\\PY{+w}{ }\\PY{o}{\\PYZlt{}}\\PY{+w}{ }\\PY{n}{T}\\PY{p}{;}\\PY{+w}{ }\\PY{n}{t}\\PY{o}{+}\\PY{o}{+}\\PY{p}{)}\\PY{+w}{ }\\PY{p}{\\PYZob{}}\n",
       "\\PY{+w}{                }\\PY{k}{const}\\PY{+w}{ }\\PY{k+kt}{float}\\PY{o}{*}\\PY{+w}{ }\\PY{n}{dout\\PYZus{}bt}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{n}{dout}\\PY{+w}{ }\\PY{o}{+}\\PY{+w}{ }\\PY{n}{b}\\PY{+w}{ }\\PY{o}{*}\\PY{+w}{ }\\PY{n}{T}\\PY{+w}{ }\\PY{o}{*}\\PY{+w}{ }\\PY{n}{OC}\\PY{+w}{ }\\PY{o}{+}\\PY{+w}{ }\\PY{n}{t}\\PY{+w}{ }\\PY{o}{*}\\PY{+w}{ }\\PY{n}{OC}\\PY{p}{;}\n",
       "\\PY{+w}{                }\\PY{k}{const}\\PY{+w}{ }\\PY{k+kt}{float}\\PY{o}{*}\\PY{+w}{ }\\PY{n}{inp\\PYZus{}bt}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{n}{inp}\\PY{+w}{ }\\PY{o}{+}\\PY{+w}{ }\\PY{n}{b}\\PY{+w}{ }\\PY{o}{*}\\PY{+w}{ }\\PY{n}{T}\\PY{+w}{ }\\PY{o}{*}\\PY{+w}{ }\\PY{n}{C}\\PY{+w}{ }\\PY{o}{+}\\PY{+w}{ }\\PY{n}{t}\\PY{+w}{ }\\PY{o}{*}\\PY{+w}{ }\\PY{n}{C}\\PY{p}{;}\n",
       "\\PY{+w}{                }\\PY{k+kt}{float}\\PY{o}{*}\\PY{+w}{ }\\PY{n}{dwrow}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{n}{dweight}\\PY{+w}{ }\\PY{o}{+}\\PY{+w}{ }\\PY{n}{o}\\PY{o}{*}\\PY{n}{C}\\PY{p}{;}\n",
       "\\PY{+w}{                }\\PY{k+kt}{float}\\PY{+w}{ }\\PY{n}{d}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{n}{dout\\PYZus{}bt}\\PY{p}{[}\\PY{n}{o}\\PY{p}{]}\\PY{p}{;}\n",
       "\\PY{+w}{                }\\PY{k}{if}\\PY{+w}{ }\\PY{p}{(}\\PY{n}{dbias}\\PY{+w}{ }\\PY{o}{!}\\PY{o}{=}\\PY{+w}{ }\\PY{n+nb}{NULL}\\PY{p}{)}\\PY{+w}{ }\\PY{p}{\\PYZob{}}\\PY{+w}{ }\\PY{n}{dbias}\\PY{p}{[}\\PY{n}{o}\\PY{p}{]}\\PY{+w}{ }\\PY{o}{+}\\PY{o}{=}\\PY{+w}{ }\\PY{n}{d}\\PY{p}{;}\\PY{+w}{ }\\PY{p}{\\PYZcb{}}\n",
       "\\PY{+w}{                }\\PY{k}{for}\\PY{+w}{ }\\PY{p}{(}\\PY{k+kt}{int}\\PY{+w}{ }\\PY{n}{i}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{l+m+mi}{0}\\PY{p}{;}\\PY{+w}{ }\\PY{n}{i}\\PY{+w}{ }\\PY{o}{\\PYZlt{}}\\PY{+w}{ }\\PY{n}{C}\\PY{p}{;}\\PY{+w}{ }\\PY{n}{i}\\PY{o}{+}\\PY{o}{+}\\PY{p}{)}\\PY{+w}{ }\\PY{p}{\\PYZob{}}\n",
       "\\PY{+w}{                    }\\PY{n}{dwrow}\\PY{p}{[}\\PY{n}{i}\\PY{p}{]}\\PY{+w}{ }\\PY{o}{+}\\PY{o}{=}\\PY{+w}{ }\\PY{n}{inp\\PYZus{}bt}\\PY{p}{[}\\PY{n}{i}\\PY{p}{]}\\PY{+w}{ }\\PY{o}{*}\\PY{+w}{ }\\PY{n}{d}\\PY{p}{;}\n",
       "\\PY{+w}{                }\\PY{p}{\\PYZcb{}}\n",
       "\\PY{+w}{            }\\PY{p}{\\PYZcb{}}\n",
       "\\PY{+w}{        }\\PY{p}{\\PYZcb{}}\n",
       "\\PY{+w}{    }\\PY{p}{\\PYZcb{}}\n",
       "\n",
       "\\PY{p}{\\PYZcb{}}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "// train_gpt2.h:226-263 (38 lines)\n",
       "void matmul_backward(float* dinp, float* dweight, float* dbias,\n",
       "                     const float* dout, const float* inp, const float* weight,\n",
       "                     int B, int T, int C, int OC) {\n",
       "    // most of the running time is spent here and in matmul_forward\n",
       "    // this backward could be done in a single \"round\" of loops\n",
       "    // but that doesn't afford an efficient parallelization strategy\n",
       "    // backward into inp first, parallelize over B,T\n",
       "\n",
       "    for (int b = 0; b < B; b++) {\n",
       "        for (int t = 0; t < T; t++) {\n",
       "            const float* dout_bt = dout + b * T * OC + t * OC;\n",
       "            float* dinp_bt = dinp + b * T * C + t * C;\n",
       "            for (int o = 0; o < OC; o++) {\n",
       "                const float* wrow = weight + o*C;\n",
       "                float d = dout_bt[o];\n",
       "                for (int i = 0; i < C; i++) {\n",
       "                    dinp_bt[i] += wrow[i] * d;\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "    // backward into weight/bias, parallelize over output channels OC\n",
       "    for (int o = 0; o < OC; o++) {\n",
       "        for (int b = 0; b < B; b++) {\n",
       "            for (int t = 0; t < T; t++) {\n",
       "                const float* dout_bt = dout + b * T * OC + t * OC;\n",
       "                const float* inp_bt = inp + b * T * C + t * C;\n",
       "                float* dwrow = dweight + o*C;\n",
       "                float d = dout_bt[o];\n",
       "                if (dbias != NULL) { dbias[o] += d; }\n",
       "                for (int i = 0; i < C; i++) {\n",
       "                    dwrow[i] += inp_bt[i] * d;\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "\n",
       "}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "render_code(\"train_gpt2.h\", show=\"matmul_backward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "# Programming Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "{    \"deletable\": false,\n",
    "    \"editable\": false}As you may imagine, this programming assignment is targeting at optimizing the most time consuming function(s) in the baseline `train_gpt2` to reducing the overall training time. In this project, your allowed to put your optimization in `my_train_gpt2.h` and we will compare the performance of `my_train_gpt2` with the baseline `train_gpt2`.\n",
    "\n",
    "## Developing and testing\n",
    "\n",
    "To save the develop time, we **strongly encourage** you to perform the testing of function optimizations using a scaled-down `test_gpt2` and `my_test_gpt2` programs. Where the `test_gpt2` include the baseline functions, and `my_test_gpt2` will use the `my_train_gpt2.h` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "→ cuDNN is manually disabled by default, run make with `USE_CUDNN=1` to try to enable\n",
      "✓ OpenMP found\n",
      "✗ NCCL is not found, disabling multi-GPU support\n",
      "---> On Linux you can try install NCCL with `sudo apt install libnccl2 libnccl-dev`\n",
      "✓ MPI enabled\n",
      "---------------------------------------------\n",
      "rm -f train_gpt2 test_gpt2 my_test_gpt2 my_train_gpt2\n",
      "rm -f build/*.o\n",
      "cc -Ofast -Wno-unused-result -Wno-ignored-pragmas -Wno-unknown-attributes -DHAVE_LINUX_PERF_EVENT_H -march=native    train_gpt2.h test_gpt2.c perfstats.o -lm -o test_gpt2\n",
      "cc -Ofast -Wno-unused-result -Wno-ignored-pragmas -Wno-unknown-attributes -DHAVE_LINUX_PERF_EVENT_H -march=native    my_train_gpt2.h my_test_gpt2.c perfstats.o -lm -o my_test_gpt2\n"
     ]
    }
   ],
   "source": [
    "!make clean test_gpt2 my_test_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the cloud for: twan012@ucr.edu\n",
      "[GPT-2]\n",
      "max_seq_len: 1024\n",
      "vocab_size: 50257\n",
      "padded_vocab_size: 50304\n",
      "num_layers: 12\n",
      "num_heads: 12\n",
      "channels: 768\n",
      "num_parameters: 124475904\n",
      "[State]\n",
      "batch_size: 4\n",
      "seq_len: 64\n",
      "num_activations: 73347840\n",
      "-43.431618, -43.431721\n",
      "-39.836346, -39.836445\n",
      "-43.065910, -43.065987\n",
      "-42.828045, -42.828156\n",
      "-43.529541, -43.529644\n",
      "-44.318398, -44.318489\n",
      "-41.227425, -41.227497\n",
      "-41.270760, -41.270847\n",
      "-42.541393, -42.541470\n",
      "-42.394997, -42.395096\n",
      "OK (LOGITS), max_diff = 8.850098e-04\n",
      "LOSS OK: 5.269998 5.270009\n",
      "dwte\n",
      "OK -0.002320 -0.002320\n",
      "OK 0.002072 0.002072\n",
      "OK 0.003717 0.003717\n",
      "OK 0.001307 0.001307\n",
      "OK 0.000632 0.000632\n",
      "TENSOR OK, maxdiff = 1.611710e-04\n",
      "dwpe\n",
      "OK -0.005111 -0.005110\n",
      "OK -0.000011 -0.000012\n",
      "OK -0.003262 -0.003262\n",
      "OK 0.009909 0.009909\n",
      "OK 0.002146 0.002145\n",
      "TENSOR OK, maxdiff = 5.031005e-06\n",
      "dln1w\n",
      "OK -0.007523 -0.007523\n",
      "OK 0.008642 0.008643\n",
      "OK 0.005025 0.005029\n",
      "OK -0.011094 -0.011095\n",
      "OK -0.001663 -0.001664\n",
      "TENSOR OK, maxdiff = 3.302675e-04\n",
      "dln1b\n",
      "OK -0.038462 -0.038458\n",
      "OK -0.030591 -0.030600\n",
      "OK 0.010215 0.010223\n",
      "OK 0.080178 0.080176\n",
      "OK -0.060908 -0.060901\n",
      "TENSOR OK, maxdiff = 1.270170e-04\n",
      "dqkvw\n",
      "OK -0.000031 -0.000031\n",
      "OK -0.000025 -0.000025\n",
      "OK -0.000064 -0.000064\n",
      "OK 0.000074 0.000074\n",
      "OK 0.000020 0.000020\n",
      "TENSOR OK, maxdiff = 5.409867e-05\n",
      "dqkvb\n",
      "OK -0.000412 -0.000411\n",
      "OK -0.000412 -0.000412\n",
      "OK 0.000114 0.000113\n",
      "OK -0.000565 -0.000565\n",
      "OK 0.000571 0.000570\n",
      "TENSOR OK, maxdiff = 3.604591e-05\n",
      "dattprojw\n",
      "OK 0.000080 0.000080\n",
      "OK -0.000005 -0.000005\n",
      "OK -0.000019 -0.000019\n",
      "OK 0.000004 0.000004\n",
      "OK 0.000031 0.000031\n",
      "TENSOR OK, maxdiff = 3.884919e-05\n",
      "dattprojb\n",
      "OK 0.000470 0.000470\n",
      "OK -0.009979 -0.009979\n",
      "OK -0.001803 -0.001804\n",
      "OK 0.037585 0.037584\n",
      "OK -0.031238 -0.031239\n",
      "TENSOR OK, maxdiff = 2.950989e-05\n",
      "dln2w\n",
      "OK -0.018318 -0.018312\n",
      "OK 0.004812 0.004813\n",
      "OK 0.008089 0.008091\n",
      "OK -0.001469 -0.001470\n",
      "OK -0.002737 -0.002737\n",
      "TENSOR OK, maxdiff = 9.146333e-04\n",
      "dln2b\n",
      "OK -0.026374 -0.026368\n",
      "OK -0.016703 -0.016695\n",
      "OK 0.001072 0.001074\n",
      "OK 0.034711 0.034711\n",
      "OK -0.028584 -0.028584\n",
      "TENSOR OK, maxdiff = 7.770956e-05\n",
      "dfcw\n",
      "OK 0.000440 0.000440\n",
      "OK -0.000000 -0.000000\n",
      "OK -0.000154 -0.000154\n",
      "OK -0.000165 -0.000165\n",
      "OK 0.000405 0.000405\n",
      "TENSOR OK, maxdiff = 7.777661e-05\n",
      "dfcb\n",
      "OK 0.003291 0.003293\n",
      "OK 0.002043 0.002043\n",
      "OK -0.001386 -0.001386\n",
      "OK 0.000386 0.000386\n",
      "OK 0.001603 0.001604\n",
      "TENSOR OK, maxdiff = 2.009189e-05\n",
      "dfcprojw\n",
      "OK 0.000680 0.000681\n",
      "OK 0.000073 0.000073\n",
      "OK -0.000416 -0.000416\n",
      "OK -0.000060 -0.000061\n",
      "OK -0.000604 -0.000604\n",
      "TENSOR OK, maxdiff = 3.759656e-05\n",
      "dfcprojb\n",
      "OK 0.003583 0.003584\n",
      "OK -0.007157 -0.007158\n",
      "OK -0.001962 -0.001964\n",
      "OK 0.001462 0.001462\n",
      "OK 0.001217 0.001217\n",
      "TENSOR OK, maxdiff = 1.167087e-05\n",
      "dlnfw\n",
      "OK -0.000022 -0.000022\n",
      "OK 0.000810 0.000811\n",
      "OK 0.001161 0.001161\n",
      "OK -0.002957 -0.002957\n",
      "OK 0.001145 0.001145\n",
      "TENSOR OK, maxdiff = 1.670569e-04\n",
      "dlnfb\n",
      "OK -0.011101 -0.011101\n",
      "OK 0.008009 0.008007\n",
      "OK -0.004771 -0.004769\n",
      "OK -0.002112 -0.002113\n",
      "OK -0.005905 -0.005905\n",
      "TENSOR OK, maxdiff = 2.922118e-05\n",
      "step 0: loss 5.269998 (took 17018.130330 ms) OK = 1\n",
      "step 1: loss 4.059700 (took 16455.478637 ms) OK = 1\n",
      "step 2: loss 3.375028 (took 16313.104565 ms) OK = 1\n",
      "step 3: loss 2.800781 (took 16310.817588 ms) OK = 1\n",
      "step 4: loss 2.315455 (took 16303.601659 ms) OK = 1\n",
      "overall okay: 1\n",
      "Total: 84734.659254 ms\n"
     ]
    }
   ],
   "source": [
    "!cs203 run \"./test_gpt2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Beyond the timestamps the code provides, you may also read the performance counter based information as we generated below. The overall code has a miss rate of 8.2%. If you want, you can insert code in the target function for more detailed profiling and you will find the target function has a cache miss rate of 16%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss: 0</th>\n",
       "      <th>Loss: 1</th>\n",
       "      <th>Loss: 2</th>\n",
       "      <th>Loss: 3</th>\n",
       "      <th>Loss: 4</th>\n",
       "      <th>IC</th>\n",
       "      <th>Cycles</th>\n",
       "      <th>CPI</th>\n",
       "      <th>CT</th>\n",
       "      <th>ET</th>\n",
       "      <th>L1_dcache_miss_rate</th>\n",
       "      <th>L1_dcache_misses</th>\n",
       "      <th>L1_dcache_accesses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.269998</td>\n",
       "      <td>4.0597</td>\n",
       "      <td>3.375028</td>\n",
       "      <td>2.800781</td>\n",
       "      <td>2.315455</td>\n",
       "      <td>518291543201</td>\n",
       "      <td>306097492151</td>\n",
       "      <td>0.590589</td>\n",
       "      <td>0.276822</td>\n",
       "      <td>84.734389</td>\n",
       "      <td>0.082032</td>\n",
       "      <td>25766053914</td>\n",
       "      <td>314098776717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loss: 0  Loss: 1   Loss: 2   Loss: 3   Loss: 4            IC  \\\n",
       "0  5.269998   4.0597  3.375028  2.800781  2.315455  518291543201   \n",
       "\n",
       "         Cycles       CPI        CT         ET   L1_dcache_miss_rate  \\\n",
       "0  306097492151  0.590589  0.276822  84.734389              0.082032   \n",
       "\n",
       "   L1_dcache_misses  L1_dcache_accesses  \n",
       "0       25766053914        314098776717  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "render_csv(\"baseline_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "As our version resides in the `my_train_gpt2.h`, we also created a program `my_test_gpt2` to evaluate the effectiveness of our optimizations. You may run the following to compile your optimized version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "→ cuDNN is manually disabled by default, run make with `USE_CUDNN=1` to try to enable\n",
      "✓ OpenMP found\n",
      "✗ NCCL is not found, disabling multi-GPU support\n",
      "---> On Linux you can try install NCCL with `sudo apt install libnccl2 libnccl-dev`\n",
      "✓ MPI enabled\n",
      "---------------------------------------------\n",
      "rm -f train_gpt2 test_gpt2 my_test_gpt2 my_train_gpt2\n",
      "rm -f build/*.o\n",
      "cc -Ofast -Wno-unused-result -Wno-ignored-pragmas -Wno-unknown-attributes -DHAVE_LINUX_PERF_EVENT_H -march=native    my_train_gpt2.h my_test_gpt2.c perfstats.o -lm -o my_test_gpt2\n"
     ]
    }
   ],
   "source": [
    "!make clean my_test_gpt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "If everything compiles, you may test your version using the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the cloud for: twan012@ucr.edu\n",
      "[GPT-2]\n",
      "max_seq_len: 1024\n",
      "vocab_size: 50257\n",
      "padded_vocab_size: 50304\n",
      "num_layers: 12\n",
      "num_heads: 12\n",
      "channels: 768\n",
      "num_parameters: 124475904\n",
      "[State]\n",
      "batch_size: 4\n",
      "seq_len: 64\n",
      "num_activations: 73347840\n",
      "-43.431618, -43.431721\n",
      "-39.836346, -39.836445\n",
      "-43.065910, -43.065987\n",
      "-42.828045, -42.828156\n",
      "-43.529541, -43.529644\n",
      "-44.318398, -44.318489\n",
      "-41.227425, -41.227497\n",
      "-41.270760, -41.270847\n",
      "-42.541393, -42.541470\n",
      "-42.394997, -42.395096\n",
      "OK (LOGITS), max_diff = 8.850098e-04\n",
      "LOSS OK: 5.269998 5.270009\n",
      "dwte\n",
      "OK -0.002320 -0.002320\n",
      "OK 0.002072 0.002072\n",
      "OK 0.003717 0.003717\n",
      "OK 0.001307 0.001307\n",
      "OK 0.000632 0.000632\n",
      "TENSOR OK, maxdiff = 1.611710e-04\n",
      "dwpe\n",
      "OK -0.005111 -0.005110\n",
      "OK -0.000011 -0.000012\n",
      "OK -0.003262 -0.003262\n",
      "OK 0.009909 0.009909\n",
      "OK 0.002146 0.002145\n",
      "TENSOR OK, maxdiff = 5.031005e-06\n",
      "dln1w\n",
      "OK -0.007523 -0.007523\n",
      "OK 0.008642 0.008643\n",
      "OK 0.005025 0.005029\n",
      "OK -0.011094 -0.011095\n",
      "OK -0.001663 -0.001664\n",
      "TENSOR OK, maxdiff = 3.302675e-04\n",
      "dln1b\n",
      "OK -0.038462 -0.038458\n",
      "OK -0.030591 -0.030600\n",
      "OK 0.010215 0.010223\n",
      "OK 0.080178 0.080176\n",
      "OK -0.060908 -0.060901\n",
      "TENSOR OK, maxdiff = 1.270170e-04\n",
      "dqkvw\n",
      "OK -0.000031 -0.000031\n",
      "OK -0.000025 -0.000025\n",
      "OK -0.000064 -0.000064\n",
      "OK 0.000074 0.000074\n",
      "OK 0.000020 0.000020\n",
      "TENSOR OK, maxdiff = 5.409867e-05\n",
      "dqkvb\n",
      "OK -0.000412 -0.000411\n",
      "OK -0.000412 -0.000412\n",
      "OK 0.000114 0.000113\n",
      "OK -0.000565 -0.000565\n",
      "OK 0.000571 0.000570\n",
      "TENSOR OK, maxdiff = 3.604591e-05\n",
      "dattprojw\n",
      "OK 0.000080 0.000080\n",
      "OK -0.000005 -0.000005\n",
      "OK -0.000019 -0.000019\n",
      "OK 0.000004 0.000004\n",
      "OK 0.000031 0.000031\n",
      "TENSOR OK, maxdiff = 3.884919e-05\n",
      "dattprojb\n",
      "OK 0.000470 0.000470\n",
      "OK -0.009979 -0.009979\n",
      "OK -0.001803 -0.001804\n",
      "OK 0.037585 0.037584\n",
      "OK -0.031238 -0.031239\n",
      "TENSOR OK, maxdiff = 2.950989e-05\n",
      "dln2w\n",
      "OK -0.018318 -0.018312\n",
      "OK 0.004812 0.004813\n",
      "OK 0.008089 0.008091\n",
      "OK -0.001469 -0.001470\n",
      "OK -0.002737 -0.002737\n",
      "TENSOR OK, maxdiff = 9.146333e-04\n",
      "dln2b\n",
      "OK -0.026374 -0.026368\n",
      "OK -0.016703 -0.016695\n",
      "OK 0.001072 0.001074\n",
      "OK 0.034711 0.034711\n",
      "OK -0.028584 -0.028584\n",
      "TENSOR OK, maxdiff = 7.770956e-05\n",
      "dfcw\n",
      "OK 0.000440 0.000440\n",
      "OK -0.000000 -0.000000\n",
      "OK -0.000154 -0.000154\n",
      "OK -0.000165 -0.000165\n",
      "OK 0.000405 0.000405\n",
      "TENSOR OK, maxdiff = 7.777661e-05\n",
      "dfcb\n",
      "OK 0.003291 0.003293\n",
      "OK 0.002043 0.002043\n",
      "OK -0.001386 -0.001386\n",
      "OK 0.000386 0.000386\n",
      "OK 0.001603 0.001604\n",
      "TENSOR OK, maxdiff = 2.009189e-05\n",
      "dfcprojw\n",
      "OK 0.000680 0.000681\n",
      "OK 0.000073 0.000073\n",
      "OK -0.000416 -0.000416\n",
      "OK -0.000060 -0.000061\n",
      "OK -0.000604 -0.000604\n",
      "TENSOR OK, maxdiff = 3.759656e-05\n",
      "dfcprojb\n",
      "OK 0.003583 0.003584\n",
      "OK -0.007157 -0.007158\n",
      "OK -0.001962 -0.001964\n",
      "OK 0.001462 0.001462\n",
      "OK 0.001217 0.001217\n",
      "TENSOR OK, maxdiff = 1.167087e-05\n",
      "dlnfw\n",
      "OK -0.000022 -0.000022\n",
      "OK 0.000810 0.000811\n",
      "OK 0.001161 0.001161\n",
      "OK -0.002957 -0.002957\n",
      "OK 0.001145 0.001145\n",
      "TENSOR OK, maxdiff = 1.670569e-04\n",
      "dlnfb\n",
      "OK -0.011101 -0.011101\n",
      "OK 0.008009 0.008007\n",
      "OK -0.004771 -0.004769\n",
      "OK -0.002112 -0.002113\n",
      "OK -0.005905 -0.005905\n",
      "TENSOR OK, maxdiff = 2.922118e-05\n",
      "step 0: loss 5.269998 (took 16031.110343 ms) OK = 1\n",
      "step 1: loss 4.059700 (took 15575.557025 ms) OK = 1\n",
      "step 2: loss 3.375028 (took 15598.219700 ms) OK = 1\n",
      "step 3: loss 2.800781 (took 15558.127268 ms) OK = 1\n",
      "step 4: loss 2.315455 (took 15565.282085 ms) OK = 1\n",
      "overall okay: 1\n",
      "Total: 80711.129871 ms\n"
     ]
    }
   ],
   "source": [
    "!cs203 run \"./my_test_gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss: 0</th>\n",
       "      <th>Loss: 1</th>\n",
       "      <th>Loss: 2</th>\n",
       "      <th>Loss: 3</th>\n",
       "      <th>Loss: 4</th>\n",
       "      <th>IC</th>\n",
       "      <th>Cycles</th>\n",
       "      <th>CPI</th>\n",
       "      <th>CT</th>\n",
       "      <th>ET</th>\n",
       "      <th>L1_dcache_miss_rate</th>\n",
       "      <th>L1_dcache_misses</th>\n",
       "      <th>L1_dcache_accesses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.269998</td>\n",
       "      <td>4.0597</td>\n",
       "      <td>3.375028</td>\n",
       "      <td>2.800781</td>\n",
       "      <td>2.315455</td>\n",
       "      <td>536062711386</td>\n",
       "      <td>292720582668</td>\n",
       "      <td>0.546057</td>\n",
       "      <td>0.275623</td>\n",
       "      <td>80.680627</td>\n",
       "      <td>0.086849</td>\n",
       "      <td>26063900230</td>\n",
       "      <td>300105355566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loss: 0  Loss: 1   Loss: 2   Loss: 3   Loss: 4            IC  \\\n",
       "0  5.269998   4.0597  3.375028  2.800781  2.315455  536062711386   \n",
       "\n",
       "         Cycles       CPI        CT         ET   L1_dcache_miss_rate  \\\n",
       "0  292720582668  0.546057  0.275623  80.680627              0.086849   \n",
       "\n",
       "   L1_dcache_misses  L1_dcache_accesses  \n",
       "0       26063900230        300105355566  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "render_csv(\"my_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Evaluation\n",
    "\n",
    "Remember, the program in the previous section is just a simplified version to test the performance. We are aiming at the complete training process with real data. Therefore, you will need to compile and test your program with the following two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "→ cuDNN is manually disabled by default, run make with `USE_CUDNN=1` to try to enable\n",
      "✓ OpenMP found\n",
      "✗ NCCL is not found, disabling multi-GPU support\n",
      "---> On Linux you can try install NCCL with `sudo apt install libnccl2 libnccl-dev`\n",
      "✓ MPI enabled\n",
      "---------------------------------------------\n",
      "rm -f train_gpt2 test_gpt2 my_test_gpt2 my_train_gpt2\n",
      "rm -f build/*.o\n",
      "cc -Ofast -Wno-unused-result -Wno-ignored-pragmas -Wno-unknown-attributes -DHAVE_LINUX_PERF_EVENT_H -march=native    my_train_gpt2.h my_train_gpt2.c perfstats.o -lm -o my_train_gpt2\n"
     ]
    }
   ],
   "source": [
    "!make clean my_train_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the cloud for: twan012@ucr.edu\n",
      "[GPT-2]\n",
      "max_seq_len: 1024\n",
      "vocab_size: 50257\n",
      "padded_vocab_size: 50304\n",
      "num_layers: 12\n",
      "num_heads: 12\n",
      "channels: 768\n",
      "num_parameters: 124475904\n",
      "train dataset num_batches: 1192\n",
      "val dataset num_batches: 128\n",
      "num_activations: 73347840\n",
      "val loss 5.325522\n",
      "step 0: train loss 4.677772 (took 16987.667222 ms)\n",
      "step 1: train loss 5.191521 (took 15741.192566 ms)\n",
      "step 2: train loss 4.438628 (took 15744.799545 ms)\n",
      "step 3: train loss 4.138455 (took 15751.149417 ms)\n",
      "step 4: train loss 4.144234 (took 15758.036754 ms)\n",
      "step 5: train loss 3.834685 (took 15733.669946 ms)\n",
      "step 6: train loss 4.298057 (took 15750.973521 ms)\n",
      "step 7: train loss 4.280747 (took 15787.745224 ms)\n",
      "step 8: train loss 4.249753 (took 15726.353762 ms)\n",
      "step 9: train loss 4.391605 (took 15723.841970 ms)\n",
      "val loss 4.416495\n",
      "generating:\n",
      "---\n",
      "grievously allowed it\n",
      "That had shall say to him:\n",
      "It is fair\n",
      "that it be paid that a villager came\n",
      "To the\n",
      "---\n",
      "step 10: train loss 3.912614 (took 15788.476854 ms)\n",
      "Total: 255142.661054 ms\n"
     ]
    }
   ],
   "source": [
    "!cs203 run \"./my_train_gpt2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "And you can see the performance counter based timing information through below. **You will need to achieve 1.2x on Gradescope (around the same speedup on our cluster) to receive full credits for this assignment. Only the performance number on Gradescope counts toward your grading**. The cluster and Gradescope use very similar CPU architectures. Therefore, the optimizations you applied should work on both sides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss: 0</th>\n",
       "      <th>Loss: 1</th>\n",
       "      <th>Loss: 2</th>\n",
       "      <th>Loss: 3</th>\n",
       "      <th>Loss: 4</th>\n",
       "      <th>Loss: 5</th>\n",
       "      <th>Loss: 6</th>\n",
       "      <th>Loss: 7</th>\n",
       "      <th>Loss: 8</th>\n",
       "      <th>Loss: 9</th>\n",
       "      <th>Loss: 10</th>\n",
       "      <th>IC</th>\n",
       "      <th>Cycles</th>\n",
       "      <th>CPI</th>\n",
       "      <th>CT</th>\n",
       "      <th>ET</th>\n",
       "      <th>L1_dcache_miss_rate</th>\n",
       "      <th>L1_dcache_misses</th>\n",
       "      <th>L1_dcache_accesses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.677772</td>\n",
       "      <td>5.191521</td>\n",
       "      <td>4.438628</td>\n",
       "      <td>4.138455</td>\n",
       "      <td>4.144234</td>\n",
       "      <td>3.834685</td>\n",
       "      <td>4.298057</td>\n",
       "      <td>4.280747</td>\n",
       "      <td>4.249753</td>\n",
       "      <td>4.391605</td>\n",
       "      <td>3.912614</td>\n",
       "      <td>1841607210898</td>\n",
       "      <td>924246705876</td>\n",
       "      <td>0.50187</td>\n",
       "      <td>0.276029</td>\n",
       "      <td>255.11903</td>\n",
       "      <td>0.097297</td>\n",
       "      <td>101777964103</td>\n",
       "      <td>1046049210461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loss: 0   Loss: 1   Loss: 2   Loss: 3   Loss: 4   Loss: 5   Loss: 6  \\\n",
       "0  4.677772  5.191521  4.438628  4.138455  4.144234  3.834685  4.298057   \n",
       "\n",
       "    Loss: 7   Loss: 8   Loss: 9  Loss: 10             IC        Cycles  \\\n",
       "0  4.280747  4.249753  4.391605  3.912614  1841607210898  924246705876   \n",
       "\n",
       "       CPI        CT         ET   L1_dcache_miss_rate  L1_dcache_misses  \\\n",
       "0  0.50187  0.276029  255.11903              0.097297      101777964103   \n",
       "\n",
       "   L1_dcache_accesses  \n",
       "0       1046049210461  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "render_csv(\"my_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deleteable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "When your submit your code for autograding, it'll run in a more tightly controlled way that let's us reliably measure performance and grade your submission. You can simulate it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"leaderboard\": [\n",
      "        {\n",
      "            \"name\": \" speedup\",\n",
      "            \"value\": 1.1465582947693083\n",
      "        }\n",
      "    ],\n",
      "    \"output\": \"\",\n",
      "    \"stdout_visibility\": \"visible\",\n",
      "    \"tests\": [\n",
      "        {\n",
      "            \"correctness\": 10,\n",
      "            \"max_score\": 100,\n",
      "            \"number\": \"1\",\n",
      "            \"output\": \"tests passed\",\n",
      "            \"score\": 94.65582947693083,\n",
      "            \"speedup\": 1.1465582947693083,\n",
      "            \"tags\": [],\n",
      "            \"visibility\": \"visible\"\n",
      "        }\n",
      "    ],\n",
      "    \"visibility\": \"visible\"\n",
      "}"
     ]
    }
   ],
   "source": [
    "! python ./autograde.py  --submission . --results -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "If you ran the original code, it gets zero points (`\"score\": 0`).  Once you correctly modify `train_gpt2.h`, you'll get 100 point.\n",
    "\n",
    "Once you are happy with your code, commit your changes to ``train_gpt2.h`.  You'll have to do this to turn it for official autograding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main e3a29b3] Yay! I finished the 2nd assignment!\n",
      " 2 files changed, 99 insertions(+), 75 deletions(-)\n",
      " delete mode 100755 my_test_gpt2\n",
      "Enumerating objects: 16, done.\n",
      "Counting objects: 100% (16/16), done.\n",
      "Delta compression using up to 20 threads\n",
      "Compressing objects: 100% (12/12), done.\n",
      "Writing objects: 100% (12/12), 19.45 KiB | 1.39 MiB/s, done.\n",
      "Total 12 (delta 9), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (9/9), completed with 4 local objects.\u001b[K\n",
      "To github.com:CS203UCR/2025fa-cs203-llm-memory-HugoWan0504.git\n",
      "   e28847b..e3a29b3  main -> main\n"
     ]
    }
   ],
   "source": [
    "!git commit -am \"Yay! I finished the 2nd assignment!\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "**If this asks you for a password, it means you forgot some initial steps in the README.md file of this repo. You'll need to interrupt your Jupyter notebook kernel and follow the exact steps in the README.md before you can start again.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "## Useful C++ Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "There are few things in C++ that might be useful in this assignment.\n",
    "\n",
    "### Controlling Compiler Optimizations\n",
    "\n",
    "First, you can prevent inlining of a particular function by declaring it like so:\n",
    "\n",
    "```\n",
    "void __attribute__((noinline)) join_solution(...)\n",
    "```\n",
    "\n",
    "This can make it easier to debug, because you can set a breakpoint on the function and it'll work like you expect.\n",
    "\n",
    "Second, you can turn on arbitrary optimizations for particular functions like so:\n",
    "\n",
    "```\n",
    "#pragma GCC push_options\n",
    "#pragma GCC optimize (\"unroll-loops\")\n",
    "\n",
    "void your_function() {\n",
    "}\n",
    "\n",
    "#pragma GCC pop_options\n",
    "```\n",
    "\n",
    "\n",
    "### Assertions\n",
    "\n",
    "The `assert()` macro is useful tool for debugging and to avoid silly errors.\n",
    "\n",
    "If you say\n",
    "\n",
    "```\n",
    "assert(a > b);\n",
    "```\n",
    "\n",
    "And the expression is not true at run time, the assert with \"fail\" your program will crash with a somewhat useful error message.\n",
    "\n",
    "This is a useful way to document and enforce assumptions you make in your code.  For instance, I used an assert in `convolution_tiled_split()` to ensure that the tile size was > 8.\n",
    "\n",
    "You can get access to  `assert()` with \n",
    "\n",
    "```\n",
    "#include<cassert>\n",
    "```\n",
    "\n",
    "The overhead of asserts is low, but not zero.  I would not put any in one of your performance-critical loops.\n",
    "\n",
    "If you want to include asserts in performance-critical areas, you can add `-DNDEBUG` to the optimizations in `config.make`.  It'll disable all the `assert()`s.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Debugging \n",
    "\n",
    "Your code will certainly have errors in it, and you'll need to debug.  THe first thing you need to do is to tone down the optimizations, because they make debugging almost impossible.  Recall that `-Og` is the right flag to use for optimization while debugging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "→ cuDNN is manually disabled by default, run make with `USE_CUDNN=1` to try to enable\n",
      "✓ OpenMP found\n",
      "✗ NCCL is not found, disabling multi-GPU support\n",
      "---> On Linux you can try install NCCL with `sudo apt install libnccl2 libnccl-dev`\n",
      "✓ MPI enabled\n",
      "---------------------------------------------\n",
      "rm -f train_gpt2 test_gpt2 my_test_gpt2 my_train_gpt2\n",
      "rm -f build/*.o\n",
      "cc -Ofast -Wno-unused-result -Wno-ignored-pragmas -Wno-unknown-attributes -DHAVE_LINUX_PERF_EVENT_H -march=native -g   my_train_gpt2.h my_test_gpt2.c perfstats.o -lm -o my_test_gpt2\n"
     ]
    }
   ],
   "source": [
    "!make clean my_test_gpt2 OPT_CFLAGS=\"-g\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Unfortunately, the Linux debugger `gdb` doesn't work inside the note book.  If you want to use it, you can do so at the terminal:\n",
    "\n",
    "```\n",
    "$ gdb ./my_test_gpt2\n",
    "GNU gdb (Ubuntu 9.2-0ubuntu1~20.04.2) 9.2\n",
    "Copyright (C) 2020 Free Software Foundation, Inc.\n",
    "License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\n",
    "This is free software: you are free to change and redistribute it.\n",
    "There is NO WARRANTY, to the extent permitted by law.\n",
    "Type \"show copying\" and \"show warranty\" for details.\n",
    "This GDB was configured as \"x86_64-linux-gnu\".\n",
    "Type \"show configuration\" for configuration details.\n",
    "For bug reporting instructions, please see:\n",
    "<http://www.gnu.org/software/gdb/bugs/>.\n",
    "Find the GDB manual and other documentation resources online at:\n",
    "    <http://www.gnu.org/software/gdb/documentation/>.\n",
    "\n",
    "For help, type \"help\".\n",
    "Type \"apropos word\" to search for commands related to \"word\"...\n",
    "Reading symbols from ./my_test_gpt2...\n",
    "(gdb) \n",
    "```\n",
    "\n",
    "The best place to start is at `matmul_backward`.  From there you can step into your solution code.\n",
    "\n",
    "```\n",
    "bash$ gdb \n",
    "(gdb) break matmul_backward\n",
    "Breakpoint 1 at 0x9fd0: matmul_backward. (2 locations)\n",
    "```\n",
    "\n",
    "Sometimes that will note give a good result, even without optimizations.  Instead, you can set a break point at a line number:\n",
    "\n",
    "```\n",
    "bash$ gdb alloc_main.exe\n",
    "(gdb) break join_solution.hpp:47\n",
    "(gdb) run --function join_solution_c --size 100  --power 2\n",
    "(gdb) list\n",
    "```\n",
    "\n",
    "There's a pretty good `gdb` [tutorial here](https://www.cs.cmu.edu/~gilpin/tutorial/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "\n",
    "## Hint\n",
    "\n",
    "As the naming of the function, this is essentially a function contains two main loops, both of which are essentially matrix-vector or matrix-matrix multiplication-like operations. This function has already performed quite a few optimizations.\n",
    "\n",
    "Let's deep dive into the code.\n",
    "\n",
    "  * **First Loop (Calculating `dinp_bt`):**\n",
    "\n",
    "    ```c++\n",
    "    for (int b = 0; b < B; ++b) {\n",
    "        for (int t = 0; t < T; ++t) {\n",
    "            const float* dout_bt = dout + (b * T + t) * OC;\n",
    "            float* dinp_bt = dinp + (b * T + t) * C;\n",
    "\n",
    "            for (int o = 0; o < OC; ++o) {\n",
    "                const float d = dout_bt[o];\n",
    "                const float* wrow = weight + o * C; // Accessing a row of 'weight'\n",
    "\n",
    "                // Cache-friendly access: contiguous wrow[i]\n",
    "                for (int i = 0; i < C; ++i) {\n",
    "                    dinp_bt[i] += wrow[i] * d;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "      * `dout_bt[o]` is accessed sequentially, which is good.\n",
    "      * `dinp_bt[i]` is accessed sequentially, which is good.\n",
    "      * `wrow[i]` (a row of `weight`) is accessed sequentially, which is good.\n",
    "      * **Potential Issue:** The `o` loop is the outermost for `weight` access within the inner `i` loop. This means that for each `(b, t)` pair, we iterate `OC` times, and each time we read a *different* row of `weight` (`wrow`). If `OC` is large and `C` is large, or if `weight` is large, `weight` rows might be evicted from cache before they are reused across `(b, t)` iterations if there was a way to reorder. However, `weight` is only read. The main write is to `dinp_bt`. `dinp_bt` is written `OC` times for each `(b,t)` slice. This means that `dinp_bt` (a `C`-sized array) is repeatedly read, modified, and written back `OC` times. If `C` is large and `OC` is large, `dinp_bt` might be evicted from cache between `o` iterations, leading to misses.\n",
    "\n",
    "  * **Second Loop (Calculating `dweight` and `dbias`):**\n",
    "\n",
    "    ```c++\n",
    "    for (int o = 0; o < OC; ++o) {\n",
    "        float* dwrow = dweight + o * C; // Writing to a row of 'dweight'\n",
    "\n",
    "        float bias_accum = 0.0f;\n",
    "\n",
    "        for (int b = 0; b < B; ++b) {\n",
    "            for (int t = 0; t < T; ++t) {\n",
    "                const float* dout_bt = dout + (b * T + t) * OC;\n",
    "                const float* inp_bt = inp + (b * T + t) * C;\n",
    "\n",
    "                const float d = dout_bt[o]; // Accesses a specific element of dout_bt\n",
    "                bias_accum += d;\n",
    "\n",
    "                for (int i = 0; i < C; ++i) {\n",
    "                    dwrow[i] += inp_bt[i] * d;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        if (dbias != NULL) {\n",
    "            dbias[o] += bias_accum;\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "      * `dwrow[i]` (a row of `dweight`) is written sequentially, which is good. This row is accumulated over all `(b, t)` iterations.\n",
    "      * `inp_bt[i]` is accessed sequentially, which is good.\n",
    "      * `dout_bt[o]` is accessed. This is the `o`-th element of `dout_bt`.\n",
    "      * **Major Cache Issue:** The outer loop is `o`. Inside, we iterate `B` then `T`. For each `o`, we iterate through all `(b, t)` pairs. This means `inp_bt` and `dout_bt` (which are essentially rows/vectors of large matrices) are accessed non-contiguously *across the `o` loop*. Specifically, `dout_bt[o]` accesses a *column* of the `dout` matrix (considering `(b*T+t)` as rows and `o` as columns). Similarly, `inp_bt[i]` is part of a `C`-sized vector, but `inp_bt` changes across `b` and `t`. This \"column-major\" like access for `dout` and `inp` within the `o` loop is a significant cache performance bottleneck.\n",
    "\n",
    "1.  **Loop Reordering (for the second loop):** The most impactful change for the second loop is to reorder the loops to maximize spatial locality. The goal is to access `dout` and `inp` sequentially.\n",
    "\n",
    "      * The `i` loop accesses `dwrow` and `inp_bt` contiguously. This should remain the innermost.\n",
    "      * The `b` and `t` loops iterate through the \"batches\" and \"time steps\" which determine the base addresses of `dout_bt` and `inp_bt`.\n",
    "      * The `o` loop iterates through the output channels/columns.\n",
    "      * If we move the `o` loop inwards, we can achieve better locality for `dout` and `inp`.\n",
    "\n",
    "2.  **Loop Tiling/Blocking (potentially for both loops, especially if `B`, `T`, `C`, `OC` are very large):** This technique breaks down the loops into smaller \"tiles\" that can fit into the cache. This helps maximize data reuse within the cache before data is evicted. This is more complex to implement and might introduce some overhead, but is crucial for very large problems.\n",
    "\n",
    "3.  **Minimizing Redundant Address Calculations:** Compilers are generally good at this, but explicit local pointers help clarity and might assist the compiler.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "**Only Gradescope Counts** The scores produced here **do not** count.  Only gradescope counts.  The results here should match what Gradescope does, but I would test your solution on Gradescope well-ahead of the deadline to ensure your code is working like you expect.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cs203.is_response": true,
    "cs203.points": 1,
    "cs203.question_type": "completeness",
    "solution2": "hidden",
    "solution2_first": true,
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<div class=\"question-text\">\n",
    "\n",
    "### References used in the project    \n",
    "\n",
    "We do not expect everyone to know the answers at the very beginning and looking for resources to solve problems is a common practice in engineering. However, it is also important to know what can you use in these assignments and give them good enough credits through citations! \n",
    "\n",
    "In real practice, not everything online can be used due to the copyright and licensing issues. Therefore, it is a nice habit to keep track of your references all the time and review if they're eligible.\n",
    "    \n",
    "In CS203, you're allowed to seek for help from the following **independently**.\n",
    "\n",
    "1. Public code repositories with proper license (e.g. MIT license) -- please provide the repos.\n",
    "2. Research papers/textbooks -- please cite them below.\n",
    "3. Generative AI -- please describe the prompt you used.\n",
    "    \n",
    "In contrast, you're **NOT allowed** to seek for help from the following.\n",
    "1. Using code from others\n",
    "2. Asking and discussing with other people except for teaching staffs.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cs203.is_response": true,
    "cs203.points": 1,
    "cs203.question_type": "completeness",
    "editable": true,
    "solution2": "hidden",
    "solution2_first": true,
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<div class=\"answer\">\n",
    "\n",
    "If you have used any outside resource to finish the programming assignment, please cite each of them properly below. Without citation to the resources you used, we will consider your assignment cheating if we found similar somewhere else.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "# Turning in the programming assignment/lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deleteable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "\n",
    "You need to turn in your notebook and your programming assignment/lab in the specific gradescope item.  \n",
    "After you complete the assignment/lab, you will turn it in by submitting your latest github repository.\n",
    "\n",
    "**Step 1:**  Save your workbook!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save your files!!\n",
      "Save your files!!\n",
      "Save your files!!\n",
      "Save your files!!\n",
      "Save your files!!\n"
     ]
    }
   ],
   "source": [
    "!for i in 1 2 3 4 5; do echo Save your files!!; sleep 1; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deleteable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "**Step 2:**  Commit everything. Please run the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deleteable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31mmy_test_gpt2\u001b[m\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n",
      "Everything up-to-date\n"
     ]
    }
   ],
   "source": [
    "!git commit -am \"Yay! I am ready to turn in!\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deleteable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "**Step 3**: \n",
    "Submit through gradescope\n",
    "You'll turn in your programming assignment by providing gradescope with your github repo of this assignment.   It'll run the autograder and return the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "347.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "610c699f0cd8c4f129acd9140687fff6866bed0eb8e82f249fc8848b827b628c"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
